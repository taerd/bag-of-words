{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c289568f",
      "metadata": {
        "id": "c289568f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "import requests\n",
        "from pymystem3 import Mystem\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import precision_score , recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c76f9b5c",
      "metadata": {
        "id": "c76f9b5c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcbad28b",
      "metadata": {
        "id": "dcbad28b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c16c23",
      "metadata": {
        "id": "01c16c23"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc715ae4",
      "metadata": {
        "id": "bc715ae4"
      },
      "outputs": [],
      "source": [
        "bigdata = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c65e5c",
      "metadata": {
        "id": "e8c65e5c"
      },
      "source": [
        "## Выгрузка данных из 3ех новостных групп в вконтакте"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5a30a85",
      "metadata": {
        "id": "e5a30a85"
      },
      "source": [
        " За тематику текстов для классификации выбрал следущее:\n",
        " Новости про covid, Спам в новостях, Непосредственно новости.\n",
        "\n",
        " Сами данные я решил сам разметить, а не выбирая сразу данные из конкретных тематик,\n",
        " например из отдельных групп с новостями про : науку, экономику, здоровье, животных и т.д.\n",
        "\n",
        " Я выбрал группы, которые выкладывают новости об всем что угодно, и пытаюсь сам их разметить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c449f1",
      "metadata": {
        "id": "b9c449f1"
      },
      "outputs": [],
      "source": [
        "#https://oauth.vk.com/authorize?client_id=7990988&display=page&scope=wall&response_type=token&v=5.131"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc44c03",
      "metadata": {
        "id": "0dc44c03"
      },
      "outputs": [],
      "source": [
        "token ='34e0cbf531055e09361376487d0bd9704478ca1072a730091388deaf4a62c22e8f2003c8e47b7cf6d481a'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc482f3",
      "metadata": {
        "id": "ccc482f3"
      },
      "outputs": [],
      "source": [
        "# https://vk.com/toporcc\n",
        "# https://vk.com/plohie_novosti_mc\n",
        "# https://vk.com/lentach\n",
        "IDS = 'toporcc','plohie_novosti_mc','lentach'\n",
        "\n",
        "for ID in IDS:\n",
        "    json_response = requests.get(('https://api.vk.com/method/wall.get?domain={}&count=100&v=5.103&access_token=' + token).\\\n",
        "                                 format(ID)).json()\n",
        "    if json_response.get('error'):\n",
        "        print(json_response.get('error'))\n",
        "    else:\n",
        "        for item in json_response['response']['items']:\n",
        "            bigdata.append(item['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad11a85",
      "metadata": {
        "id": "3ad11a85",
        "outputId": "b6bd781f-f12f-426c-9fe3-b37e261a50d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(bigdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac9fae7b",
      "metadata": {
        "id": "ac9fae7b"
      },
      "source": [
        "## Разметка выгруженных данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964103f3",
      "metadata": {
        "id": "964103f3"
      },
      "source": [
        " Данный способ имеет большую погрешность в разметке, потому, что 'ключевые слова' из различных классов могут быть употреблены\n",
        "\n",
        " В другом классе, но при этом этот алгоритм разметки отнесет его в класс по 'ключевому слову'\n",
        "\n",
        " Лучше смотреть на смысловую часть предложений\\кусков текста используя готовые методы из NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "189183b2",
      "metadata": {
        "id": "189183b2"
      },
      "outputs": [],
      "source": [
        "spamwords = ['кредит','заем','займ','подарить','промокод','активация','выгода','халявный','резюме','smartzaem']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ccd0948",
      "metadata": {
        "id": "3ccd0948"
      },
      "outputs": [],
      "source": [
        "covidwords = ['коронавирус','вирус','заболеть','болеть','больной','заражать','пандемия','coronavirus','вакцинация']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7d5270",
      "metadata": {
        "id": "2a7d5270"
      },
      "outputs": [],
      "source": [
        "m = Mystem()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba58c1f",
      "metadata": {
        "id": "8ba58c1f"
      },
      "outputs": [],
      "source": [
        "def lemmatize_sentence(text):\n",
        "    lemmas=m.lemmatize(text)\n",
        "    return \"\".join(lemmas).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0990807e",
      "metadata": {
        "id": "0990807e"
      },
      "outputs": [],
      "source": [
        "spam = []\n",
        "covid = []\n",
        "news = []\n",
        "\n",
        "testset = []\n",
        "dataset = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4cb15b",
      "metadata": {
        "id": "6e4cb15b"
      },
      "outputs": [],
      "source": [
        "# ~20% из данных будут тестом\n",
        "\n",
        "# Русские стоп слова, их нужно отбросить (союзы,предлоги)\n",
        "stop_words = stopwords.words(\"russian\")\n",
        "\n",
        "for data in bigdata:\n",
        "\n",
        "    if np.random.rand(1)>0.2:\n",
        "\n",
        "        # Приведение слов к их инфинитиву\n",
        "        doc = lemmatize_sentence(data)\n",
        "        # Разбиение на слова предложения\n",
        "        tokens_data=re.split(r'[-\\s\\n\\t-:\\[\\]<>\\'.,;!?()\" ]+',doc)\n",
        "\n",
        "        words_data = []\n",
        "\n",
        "        # Получение выборки\n",
        "        for token_data in tokens_data:\n",
        "            if ((token_data not in stop_words) and (len(token_data)>3)):\n",
        "\n",
        "                words_data.append(token_data)\n",
        "\n",
        "\n",
        "        # Разметка данных\n",
        "        c=0\n",
        "\n",
        "        for spamword in spamwords:\n",
        "            if spamword in words_data:\n",
        "                spam.append(words_data)\n",
        "                #dataset.append([words_data,0])\n",
        "                c+=1\n",
        "                break\n",
        "\n",
        "        if c==0:\n",
        "            for covidword in covidwords:\n",
        "                if covidword in words_data:\n",
        "                    covid.append(words_data)\n",
        "                    #dataset.append([words_data,1])\n",
        "                    c+=1\n",
        "                    break\n",
        "\n",
        "        if c==0:\n",
        "            news.append(words_data)\n",
        "            #dataset.append([words_data,2])\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Приведение слов к их инфинитиву\n",
        "        doc = lemmatize_sentence(data)\n",
        "        # Разбиение на слова предложения\n",
        "        tokens_data=re.split(r'[-\\s\\n\\t-:\\[\\]<>\\'.,;!?()\" ]+',doc)\n",
        "\n",
        "        # Получение выборки\n",
        "        words_data = []\n",
        "\n",
        "        for token_data in tokens_data:\n",
        "            if ((token_data not in stop_words) and (len(token_data)>3)):\n",
        "                words_data.append(token_data)\n",
        "\n",
        "        # Заполнение тестового датасета\n",
        "        testset.append(words_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8dcf1e",
      "metadata": {
        "id": "3c8dcf1e"
      },
      "outputs": [],
      "source": [
        "dataset = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637f34c9",
      "metadata": {
        "id": "637f34c9"
      },
      "outputs": [],
      "source": [
        "def upd_dataset(array,num_class):\n",
        "    for data in array:\n",
        "        dataset.append([data,num_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b41dfeeb",
      "metadata": {
        "id": "b41dfeeb"
      },
      "outputs": [],
      "source": [
        "upd_dataset(spam,0)\n",
        "upd_dataset(covid,1)\n",
        "upd_dataset(news,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2718ddbc",
      "metadata": {
        "id": "2718ddbc",
        "outputId": "67e6d5b0-cd2c-4788-aa34-f5b6ce9fb1e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Объем тестовой выборки\n",
        "len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa137ee4",
      "metadata": {
        "id": "fa137ee4",
        "outputId": "5bd33976-bff9-41da-ff4f-0c5f5e01b705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "232"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Объем тренировочной выборки\n",
        "len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59bca88a",
      "metadata": {
        "id": "59bca88a"
      },
      "source": [
        "## Обучение (Наивный байесовский классификатор)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62700610",
      "metadata": {
        "id": "62700610"
      },
      "outputs": [],
      "source": [
        "def fit (dataset, alpha):\n",
        "    classes, freq, tot_in_cl, total = {}, {}, {}, set()\n",
        "    for features, label in dataset:\n",
        "        if label not in classes:\n",
        "            classes[label] = 0\n",
        "            tot_in_cl[label] = 0\n",
        "        classes[label] += 1\n",
        "        for feature in features:\n",
        "            if (feature,label) not in freq:\n",
        "                freq[(feature,label)] = 0\n",
        "            freq[(feature,label)] += 1\n",
        "            tot_in_cl[label] += 1\n",
        "            total.add(feature)\n",
        "\n",
        "\n",
        "    # Перевод на язык вероятностей\n",
        "    # Частоты слов\n",
        "    for feature,label in freq:\n",
        "        freq[(feature,label)] = ((alpha + freq[(feature,label)] ) /  (alpha * len(total) + tot_in_cl[label]) )\n",
        "\n",
        "    # Частоты классов\n",
        "    for cl in classes:\n",
        "        classes[cl] /= len(dataset)\n",
        "\n",
        "\n",
        "    return alpha,classes, freq, tot_in_cl, len(total)\n",
        "\n",
        "def predict(classifier , features):\n",
        "    alpha, classes, freq, tot_in_cl, len_total = classifier\n",
        "    # Лямбда функция\n",
        "    return max(classes.keys(),\n",
        "              key = lambda cl:\n",
        "              np.log10(classes[cl]) +\n",
        "                sum(np.log10(freq.get((feature,cl), alpha/(alpha*len_total+tot_in_cl[cl])) )  \\\n",
        "                  for feature in features ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212c981b",
      "metadata": {
        "id": "212c981b"
      },
      "outputs": [],
      "source": [
        "model = fit(dataset,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b33816",
      "metadata": {
        "id": "08b33816",
        "outputId": "5a4f8204-b33e-41db-e909-a2323c319891"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model_dict.pkl']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Сохранение обученной модели\n",
        "#joblib.dump(model,'model_dict.pkl')\n",
        "\n",
        "# Использование обученной модели\n",
        "#model = joblib.load('model_dict.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dccc8aed",
      "metadata": {
        "id": "dccc8aed"
      },
      "source": [
        "## Разметка тестовых данных (y) ,  и прогнозирование модели (y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a807095",
      "metadata": {
        "id": "4a807095"
      },
      "outputs": [],
      "source": [
        "y = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b70fad",
      "metadata": {
        "id": "b2b70fad"
      },
      "outputs": [],
      "source": [
        "for test in testset:\n",
        "    c = 0\n",
        "    for spamword in spamwords:\n",
        "        if spamword in test:\n",
        "            y.append(0)\n",
        "            c+=1\n",
        "            break\n",
        "\n",
        "    if c==0:\n",
        "        for covidword in covidwords:\n",
        "            if covidword in test:\n",
        "                y.append(1)\n",
        "                c+=1\n",
        "                break\n",
        "\n",
        "    if c==0:\n",
        "        y.append(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494a852e",
      "metadata": {
        "id": "494a852e"
      },
      "outputs": [],
      "source": [
        "y_pred = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c80a48a",
      "metadata": {
        "id": "4c80a48a"
      },
      "outputs": [],
      "source": [
        "for testdata in testset:\n",
        "    y_pred.append(predict(model,testdata))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3d425f",
      "metadata": {
        "id": "af3d425f"
      },
      "source": [
        "# Подсчет F меры, так как классы не сбалансированы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8fc82dd",
      "metadata": {
        "id": "d8fc82dd"
      },
      "outputs": [],
      "source": [
        "pr_score = precision_score(y,y_pred,average = 'micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "017bb428",
      "metadata": {
        "id": "017bb428"
      },
      "outputs": [],
      "source": [
        "rec_score = recall_score(y, y_pred,average = 'micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da83d6b2",
      "metadata": {
        "id": "da83d6b2"
      },
      "outputs": [],
      "source": [
        "F = pr_score*rec_score/(pr_score+rec_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c991791",
      "metadata": {
        "id": "9c991791",
        "outputId": "b43dc255-d381-44cc-afca-72a078071317"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3382352941176471"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}